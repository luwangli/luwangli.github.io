---
layout:     post
title:      软件定义路由
subtitle:   为何从硬件走向软件
date:       2020-05-09
author:     BY beta
header-img: img/2020-05-09/head.jpg
catalog:    true
tags:
    - linux
    - 软件定义网络
---

## 前言
软件定义网络已经在学术界研究很久，其实互联网非常重要的一个特性就是“软”，“软”特性
相较于那些结构固定的设施而言，意味着更新迭代迅速，快速适应新需求。  
```
我记得本科上C++课时，老师提到，为何现在计算机可以发展的如此迅速，其特性就是“软”。
一个跨海大桥建造需要几年，三峡大坝需要十几年，这些硬结构设施往往是不可改变的，无法
及时应对新的需求。而对于计算机软件而言，我们可以随时删除、增加、修改功能，这正是计算机的
魅力。
```
但是，让人非常奇怪的是，互联网的上层应用日新月异，然而底部的基础设施却几乎没有改变。
如果接触过网络管理，就会发现配置各类路由协议是一个让人非常头疼的事情，不仅很麻烦，
而且各个硬件厂商都有自己的配置风格，更别提专有协议之类。
## 1.软件定义网络
软件定义网络，其本质就是使用计算机科学中最常用的「虚拟机」构想，将传统由硬件实现
的 交换、网关、路由、NAT 等网络流量控制流程交由软件来统一管理：可以实现硬件不动，
网络结构瞬间变化，避免了传统的停机维护调试的烦恼，也为大规模公有云计算铺平了道路。
## 2 软路由的特点
### 2.1价格低
当前的民用顶级 CPU 的性能已经爆表，因为规模巨大，所以其价格也要显著低于同性能的
专用处理器：自建 40G 软路由的价格大约是 40G 专用路由价格的二十分之一
### 2.2可编程
可编程意味着开发人员可以根据特定场景的需要，定制软路由实现高效路由；同时也可快速
更新以适应网络场景的变化。
### 2.3性能低下
传统 *UNIX 网络栈的性能实在是不高。Unix 进程在网络数据包过来的时候，要进行一次
上下文切换，需要分别读写一次内存，当系统网络栈处理完数据把数据交给用户态的进程
如 Nginx 去处理还会出现一次上下文切换，还要分别读写一次内存。一共 1200 个 CPU 
周期呀，太浪费了。
## 3 DPDK
在2.3我们知道，软路由的最大瓶颈在于性能低下。为了克服这个瓶颈，业界提出了DPDK
DPDK 是 SDN 更前沿的方向：使用 x86 通用 CPU 实现 10Gbps 甚至 40Gbps 的超高速网关（路由器）

### 3.1 DPDK技术
Intel DPDK 全称为 Intel Data Plane Development Kit，直译为「英特尔数据平面开发
工具集」，它可以摆脱 *UNIX 网络数据包处理机制的局限，实现超高速的网络包处理。  
### 3.2 DPDK如何实现超高速网络包处理
#### 3.2.1使用用户态网络栈

DPDK 使用自研的数据链路层（MAC 地址）和网络层（ip 地址）处理功能（协议栈），
抛弃操作系统（Linux，BSD 等）提供的网络处理功能（协议栈），直接接管物理网卡，
在用户态处理数据包，并且配合大页内存和 NUMA 等技术，大幅提升了网络性能。
有论文做过实测，10G 网卡使用 Linux 网络协议栈只能跑到 2G 多，而 DPDK 分分钟跑满

#### 3.2.2 NUMA
NUMA 来源于 AMD Opteron 微架构，其特点是将 CPU 直接和某几根内存使用总线电路连接
在一起，这样 CPU 在读取自己拥有的内存的时候就会很快，代价就是读取别 U 的内存的时
候就会比较慢。这个技术伴随着服务器 CPU 核心数越来越多，内存总量越来越大的趋势下
诞生的，因为传统的模型中不仅带宽不足，而且极易被抢占，效率下降的厉害

#### 3.2.3 大页内存
内存分页 
为了实现虚拟内存管理机制，前人们发明了内存分页机制。这个技术诞生的时候，
内存分页的默认大小是 4KB，而到了今天，绝大多数操作系统还是用的这个数字，
但是内存的容量已经增长了不知道多少倍了。  

TLB miss
TLB（Translation Lookaside Buffers）转换检测缓冲区，是内存控制器中为增
虚拟地址到物理地址的翻译速度而设立的一组电子元件，最近十几年已经随着内存
控制器被集成到了 CPU 内部，每颗 CPU 的 TLB 都有固定的长度。
如果缓存未命中（TLB miss），则要付出 20-30 个 CPU 周期的带价。假设应用程序
需要 2MB 的内存，如果操作系统以 4KB 作为分页的单位，则需要 512 个页面，
进而在 TLB 中需要 512 个表项，同时也需要 512 个页表项，操作系统需要经历
至少 512 次 TLB Miss 和 512 次缺页中断才能将 2MB 应用程序空间全部映射到
物理内存；然而，当操作系统采用 2MB 作为分页的基本单位时，只需要一次 TLB Miss 
和一次缺页中断，就可以为 2MB 的应用程序空间建立虚实映射，并在运行过程中无需再
经历 TLB Miss 和缺页中断。

大页内存

大页内存 HugePage 是一种非常有效的减少 TLB miss 的方式，让我们来进行一个
简单的计算。

2013 年发布的 Intel Haswell i7-4770 是当年的民用旗舰 CPU，其在使用 64 位 
Windows 系统时，可以提供 1024 长度的 TLB，如果内存页的大小是 4KB，那么
总缓存内存容量为 4MB，如果内存页的大小是 2MB，那么总缓存内存容量为 2GB。
显然后者的 TLB miss 概率会低得多。
DPDK 支持 1G 的内存分页配置，这种模式下，一次性缓存的内存容量高达 1TB，
绝对够用了。
不过大页内存的效果没有理论上那么惊人，DPDK 实测有 10%~15% 的性能提升，
原因依旧是那个天生就带的涡轮：局部性。
## 4参考文献
1. https://www.jiqizhixin.com/articles/2018-12-18-11
